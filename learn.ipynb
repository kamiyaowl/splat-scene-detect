{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splatoon2のシーン分析\n",
    "\n",
    "## モチベーション\n",
    "\n",
    "録画を切り出す際の境界検出ができたらハッピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数とか\n",
    "\n",
    "# 元データ保存先\n",
    "dataset_base_path = '.\\\\splat-scene-dataset'\n",
    "dataset_split_base_path = '.\\\\dataset'\n",
    "tensorboard_log_path = '.\\\\tflog'\n",
    "\n",
    "# データセットの分離比率\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 画像設定\n",
    "input_size = (640, 360)\n",
    "input_shape = (640, 360, 3)\n",
    "\n",
    "# データ関係\n",
    "batch_size = 4\n",
    "categories_n = 17\n",
    "\n",
    "dataset_train_path = os.path.join(dataset_split_base_path, 'train')\n",
    "dataset_val_path   = os.path.join(dataset_split_base_path, 'val')\n",
    "dataset_test_path  = os.path.join(dataset_split_base_path, 'test')\n",
    "pathes = [dataset_train_path, dataset_val_path, dataset_test_path]\n",
    "\n",
    "ratios = [train_ratio, val_ratio, test_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['battle', 'battle_finish', 'battle_loby', 'battle_matching', 'battle_result', 'battle_rule', 'battle_start', 'loading', 'menu', 'other', 'salmon', 'salmon_lobby', 'salmon_matching', 'salmon_miss', 'salmon_result', 'salmon_start', 'weapon_select']\n",
      "battle 9558 [5734, 1911, 1911]\n",
      "Mkdir .\\dataset\\train\\battle\n",
      "Mkdir .\\dataset\\val\\battle\n",
      "Mkdir .\\dataset\\test\\battle\n",
      "battle 5734 .\\dataset\\train 5734\n",
      "battle 1911 .\\dataset\\val 1911\n",
      "battle 1911 .\\dataset\\test 1911\n",
      "battle_finish 215 [129, 43, 43]\n",
      "Mkdir .\\dataset\\train\\battle_finish\n",
      "Mkdir .\\dataset\\val\\battle_finish\n",
      "Mkdir .\\dataset\\test\\battle_finish\n",
      "battle_finish 129 .\\dataset\\train 129\n",
      "battle_finish 43 .\\dataset\\val 43\n",
      "battle_finish 43 .\\dataset\\test 43\n",
      "battle_loby 280 [168, 56, 56]\n",
      "Mkdir .\\dataset\\train\\battle_loby\n",
      "Mkdir .\\dataset\\val\\battle_loby\n",
      "Mkdir .\\dataset\\test\\battle_loby\n",
      "battle_loby 168 .\\dataset\\train 168\n",
      "battle_loby 56 .\\dataset\\val 56\n",
      "battle_loby 56 .\\dataset\\test 56\n",
      "battle_matching 1376 [825, 275, 275]\n",
      "Mkdir .\\dataset\\train\\battle_matching\n",
      "Mkdir .\\dataset\\val\\battle_matching\n",
      "Mkdir .\\dataset\\test\\battle_matching\n",
      "battle_matching 825 .\\dataset\\train 825\n",
      "battle_matching 275 .\\dataset\\val 275\n",
      "battle_matching 275 .\\dataset\\test 275\n",
      "battle_result 1265 [759, 253, 253]\n",
      "Mkdir .\\dataset\\train\\battle_result\n",
      "Mkdir .\\dataset\\val\\battle_result\n",
      "Mkdir .\\dataset\\test\\battle_result\n",
      "battle_result 759 .\\dataset\\train 759\n",
      "battle_result 253 .\\dataset\\val 253\n",
      "battle_result 253 .\\dataset\\test 253\n",
      "battle_rule 256 [153, 51, 51]\n",
      "Mkdir .\\dataset\\train\\battle_rule\n",
      "Mkdir .\\dataset\\val\\battle_rule\n",
      "Mkdir .\\dataset\\test\\battle_rule\n",
      "battle_rule 153 .\\dataset\\train 153\n",
      "battle_rule 51 .\\dataset\\val 51\n",
      "battle_rule 51 .\\dataset\\test 51\n",
      "battle_start 302 [181, 60, 60]\n",
      "Mkdir .\\dataset\\train\\battle_start\n",
      "Mkdir .\\dataset\\val\\battle_start\n",
      "Mkdir .\\dataset\\test\\battle_start\n",
      "battle_start 181 .\\dataset\\train 181\n",
      "battle_start 60 .\\dataset\\val 60\n",
      "battle_start 60 .\\dataset\\test 60\n",
      "loading 553 [331, 110, 110]\n",
      "Mkdir .\\dataset\\train\\loading\n",
      "Mkdir .\\dataset\\val\\loading\n",
      "Mkdir .\\dataset\\test\\loading\n",
      "loading 331 .\\dataset\\train 331\n",
      "loading 110 .\\dataset\\val 110\n",
      "loading 110 .\\dataset\\test 110\n",
      "menu 17 [10, 3, 3]\n",
      "Mkdir .\\dataset\\train\\menu\n",
      "Mkdir .\\dataset\\val\\menu\n",
      "Mkdir .\\dataset\\test\\menu\n",
      "menu 10 .\\dataset\\train 10\n",
      "menu 3 .\\dataset\\val 3\n",
      "menu 3 .\\dataset\\test 3\n",
      "other 16 [9, 3, 3]\n",
      "Mkdir .\\dataset\\train\\other\n",
      "Mkdir .\\dataset\\val\\other\n",
      "Mkdir .\\dataset\\test\\other\n",
      "other 9 .\\dataset\\train 9\n",
      "other 3 .\\dataset\\val 3\n",
      "other 3 .\\dataset\\test 3\n",
      "salmon 2664 [1598, 532, 532]\n",
      "Mkdir .\\dataset\\train\\salmon\n",
      "Mkdir .\\dataset\\val\\salmon\n",
      "Mkdir .\\dataset\\test\\salmon\n",
      "salmon 1598 .\\dataset\\train 1598\n",
      "salmon 532 .\\dataset\\val 532\n",
      "salmon 532 .\\dataset\\test 532\n",
      "salmon_lobby 17 [10, 3, 3]\n",
      "Mkdir .\\dataset\\train\\salmon_lobby\n",
      "Mkdir .\\dataset\\val\\salmon_lobby\n",
      "Mkdir .\\dataset\\test\\salmon_lobby\n",
      "salmon_lobby 10 .\\dataset\\train 10\n",
      "salmon_lobby 3 .\\dataset\\val 3\n",
      "salmon_lobby 3 .\\dataset\\test 3\n",
      "salmon_matching 128 [76, 25, 25]\n",
      "Mkdir .\\dataset\\train\\salmon_matching\n",
      "Mkdir .\\dataset\\val\\salmon_matching\n",
      "Mkdir .\\dataset\\test\\salmon_matching\n",
      "salmon_matching 76 .\\dataset\\train 76\n",
      "salmon_matching 25 .\\dataset\\val 25\n",
      "salmon_matching 25 .\\dataset\\test 25\n",
      "salmon_miss 23 [13, 4, 4]\n",
      "Mkdir .\\dataset\\train\\salmon_miss\n",
      "Mkdir .\\dataset\\val\\salmon_miss\n",
      "Mkdir .\\dataset\\test\\salmon_miss\n",
      "salmon_miss 13 .\\dataset\\train 13\n",
      "salmon_miss 4 .\\dataset\\val 4\n",
      "salmon_miss 4 .\\dataset\\test 4\n",
      "salmon_result 157 [94, 31, 31]\n",
      "Mkdir .\\dataset\\train\\salmon_result\n",
      "Mkdir .\\dataset\\val\\salmon_result\n",
      "Mkdir .\\dataset\\test\\salmon_result\n",
      "salmon_result 94 .\\dataset\\train 94\n",
      "salmon_result 31 .\\dataset\\val 31\n",
      "salmon_result 31 .\\dataset\\test 31\n",
      "salmon_start 79 [47, 15, 15]\n",
      "Mkdir .\\dataset\\train\\salmon_start\n",
      "Mkdir .\\dataset\\val\\salmon_start\n",
      "Mkdir .\\dataset\\test\\salmon_start\n",
      "salmon_start 47 .\\dataset\\train 47\n",
      "salmon_start 15 .\\dataset\\val 15\n",
      "salmon_start 15 .\\dataset\\test 15\n",
      "weapon_select 157 [94, 31, 31]\n",
      "Mkdir .\\dataset\\train\\weapon_select\n",
      "Mkdir .\\dataset\\val\\weapon_select\n",
      "Mkdir .\\dataset\\test\\weapon_select\n",
      "weapon_select 94 .\\dataset\\train 94\n",
      "weapon_select 31 .\\dataset\\val 31\n",
      "weapon_select 31 .\\dataset\\test 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugするたびに結果が変わるのはひとまず避けたい\n",
    "random.seed(0)\n",
    "\n",
    "# learn/validate/testに分離\n",
    "def split_dataset(src_base_path, dst_base_path, pathes, ratios, debug=False):\n",
    "    # すでに作成されている場合は一旦削除\n",
    "    if (os.path.exists(dst_base_path)):\n",
    "        shutil.rmtree(dst_base_path)\n",
    "    # ディレクトリ作成\n",
    "    os.mkdir(dst_base_path)\n",
    "    for p in pathes:\n",
    "        os.mkdir(p)\n",
    "    # ディレクトリ一覧取得\n",
    "    categories = list(filter(lambda x: \n",
    "                             os.path.isdir(os.path.join(src_base_path, x)) \n",
    "                             and not(x.startswith('.')),\n",
    "                     os.listdir(dataset_base_path)))\n",
    "    categories_n = len(categories) # 返却値にしてあげる\n",
    "    print(categories)\n",
    "    # 順番にコピーしてく\n",
    "    for c in categories:\n",
    "        files = os.listdir(os.path.join(src_base_path, c))\n",
    "        files_count = len(files)\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        ratio_sum = sum(ratios)\n",
    "        take_count = [int(files_count * (r / ratio_sum)) for r in ratios]\n",
    "        print(c, files_count, take_count)\n",
    "\n",
    "        for p in pathes:\n",
    "            dst = os.path.join(p, c)\n",
    "            if debug:\n",
    "                print('Mkdir {}'.format(dst))\n",
    "            os.mkdir(dst)\n",
    "            \n",
    "        count = 0\n",
    "        for t, p in zip(take_count, pathes):\n",
    "            target_files = files[count:count + t]\n",
    "            print(c, t, p, len(target_files))\n",
    "            src = [os.path.join(src_base_path, c, tf) for tf in target_files]\n",
    "            dst = [os.path.join(p, c, tf) for tf in target_files]\n",
    "            for s, d in zip(src, dst):\n",
    "                # print('Copy {} -> {}'.format(s, d))\n",
    "                shutil.copyfile(s, d)\n",
    "            count = t\n",
    "        if debug:\n",
    "            print('{} copy {} files'.format(c, count))\n",
    "    return categories_n\n",
    "        \n",
    "split_dataset(dataset_base_path, dataset_split_base_path, pathes, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\dataset\\train\n",
      "Found 10231 images belonging to 17 classes.\n",
      ".\\dataset\\val\n",
      "Found 3406 images belonging to 17 classes.\n",
      ".\\dataset\\test\n",
      "Found 3406 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# イメージをいい感じに読み込んでもらう\n",
    "def create_generator(path,\n",
    "                     target_size = (640, 360),\n",
    "                     batch_size = 16,\n",
    "                     class_mode = 'categorical'):\n",
    "    print(path)\n",
    "    dg = ImageDataGenerator(rescale=1/255.0)\n",
    "    gen = dg.flow_from_directory(path, \n",
    "                                 target_size=target_size,\n",
    "                                 batch_size=batch_size,\n",
    "                                 class_mode=class_mode,\n",
    "                                 shuffle=True)\n",
    "    return (dg, gen)\n",
    "\n",
    "(train_dg, train_gen) = create_generator(dataset_train_path, target_size=input_size, batch_size=batch_size)\n",
    "(val_dg,   val_gen)   = create_generator(dataset_val_path, target_size=input_size, batch_size=batch_size)\n",
    "(test_dg,  test_gen)  = create_generator(dataset_test_path, target_size=input_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 640, 360, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 640, 360, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 640, 360, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 320, 180, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 320, 180, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 320, 180, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 160, 90, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 160, 90, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 160, 90, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 160, 90, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 80, 45, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 80, 45, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 80, 45, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 80, 45, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 40, 22, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 40, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 40, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 40, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 20, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 15,257,425\n",
      "Trainable params: 542,737\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGGの転移学習モデルを作る\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "def create_vgg16_base_model(categories_n):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    # VGG16自体は学習できないように凍結しておく\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = False\n",
    "    # あとにレイヤを追加\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(categories_n, activation='softmax')(x)\n",
    "    return Model(inputs= base_model.input, outputs=x)\n",
    "    \n",
    "model = create_vgg16_base_model(categories_n)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2558/2558 [==============================] - 1070s 418ms/step - loss: 0.2455 - acc: 0.9331 - val_loss: 0.2712 - val_acc: 0.9180\n",
      "Epoch 2/50\n",
      "2558/2558 [==============================] - 1001s 391ms/step - loss: 0.2436 - acc: 0.9339 - val_loss: 0.2208 - val_acc: 0.9473\n",
      "Epoch 3/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2394 - acc: 0.9363 - val_loss: 0.2186 - val_acc: 0.9414\n",
      "Epoch 4/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2367 - acc: 0.9372 - val_loss: 0.2096 - val_acc: 0.9473\n",
      "Epoch 5/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2352 - acc: 0.9375 - val_loss: 0.2374 - val_acc: 0.9238\n",
      "Epoch 6/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2297 - acc: 0.9386 - val_loss: 0.2234 - val_acc: 0.9375\n",
      "Epoch 7/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2286 - acc: 0.9370 - val_loss: 0.2238 - val_acc: 0.9373\n",
      "Epoch 8/50\n",
      "2558/2558 [==============================] - 999s 391ms/step - loss: 0.2238 - acc: 0.9396 - val_loss: 0.2062 - val_acc: 0.9414\n",
      "Epoch 9/50\n",
      "2558/2558 [==============================] - 1000s 391ms/step - loss: 0.2207 - acc: 0.9406 - val_loss: 0.2259 - val_acc: 0.9141\n",
      "Epoch 10/50\n",
      "2558/2558 [==============================] - 1000s 391ms/step - loss: 0.2194 - acc: 0.9410 - val_loss: 0.2348 - val_acc: 0.9277\n",
      "Epoch 11/50\n",
      "2558/2558 [==============================] - 1000s 391ms/step - loss: 0.2154 - acc: 0.9424 - val_loss: 0.2115 - val_acc: 0.9336\n",
      "Epoch 12/50\n",
      "2451/2558 [===========================>..] - ETA: 39s - loss: 0.2125 - acc: 0.9439"
     ]
    }
   ],
   "source": [
    "# 学習する\n",
    "tb_cb = TensorBoard(log_dir=tensorboard_log_path)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    epochs = 50,\n",
    "    verbose = 1,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=128,\n",
    "    callbacks=[tb_cb],\n",
    ")\n",
    "model.save('model.h5')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852/852 [==============================] - 395s 463ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27528655233144095, 0.9116265413975337]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータで性能確認\n",
    "result = model.evaluate_generator(\n",
    "    test_gen,\n",
    "    verbose=1\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
