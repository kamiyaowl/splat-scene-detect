{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splatoon2のシーン分析\n",
    "\n",
    "## モチベーション\n",
    "\n",
    "録画を切り出す際の境界検出ができたらハッピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "print(sys.version)\n",
    "# print(sys.executable)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数とか\n",
    "\n",
    "# 元データ保存先\n",
    "dataset_base_path = '.\\\\splat-scene-dataset'\n",
    "dataset_split_base_path = '.\\\\dataset'\n",
    "tensorboard_log_path = '.\\\\tflog'\n",
    "\n",
    "# データセットの分離比率\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 画像設定\n",
    "input_size = (80, 45)\n",
    "input_shape = (80, 45, 3)\n",
    "\n",
    "# データ関係\n",
    "batch_size = 4\n",
    "categories_n = 17\n",
    "\n",
    "dataset_train_path = os.path.join(dataset_split_base_path, 'train')\n",
    "dataset_val_path   = os.path.join(dataset_split_base_path, 'val')\n",
    "dataset_test_path  = os.path.join(dataset_split_base_path, 'test')\n",
    "pathes = [dataset_train_path, dataset_val_path, dataset_test_path]\n",
    "\n",
    "ratios = [train_ratio, val_ratio, test_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['battle', 'battle_finish', 'battle_loby', 'battle_matching', 'battle_result', 'battle_rule', 'battle_start', 'loading', 'menu', 'other', 'salmon', 'salmon_lobby', 'salmon_matching', 'salmon_miss', 'salmon_result', 'salmon_start', 'weapon_select']\n",
      "battle 9558 [5734, 1911, 1911]\n",
      "Mkdir .\\dataset\\train\\battle\n",
      "Mkdir .\\dataset\\val\\battle\n",
      "Mkdir .\\dataset\\test\\battle\n",
      "battle 5734 .\\dataset\\train 5734\n",
      "battle 1911 .\\dataset\\val 1911\n",
      "battle 1911 .\\dataset\\test 1911\n",
      "battle_finish 215 [129, 43, 43]\n",
      "Mkdir .\\dataset\\train\\battle_finish\n",
      "Mkdir .\\dataset\\val\\battle_finish\n",
      "Mkdir .\\dataset\\test\\battle_finish\n",
      "battle_finish 129 .\\dataset\\train 129\n",
      "battle_finish 43 .\\dataset\\val 43\n",
      "battle_finish 43 .\\dataset\\test 43\n",
      "battle_loby 280 [168, 56, 56]\n",
      "Mkdir .\\dataset\\train\\battle_loby\n",
      "Mkdir .\\dataset\\val\\battle_loby\n",
      "Mkdir .\\dataset\\test\\battle_loby\n",
      "battle_loby 168 .\\dataset\\train 168\n",
      "battle_loby 56 .\\dataset\\val 56\n",
      "battle_loby 56 .\\dataset\\test 56\n",
      "battle_matching 1376 [825, 275, 275]\n",
      "Mkdir .\\dataset\\train\\battle_matching\n",
      "Mkdir .\\dataset\\val\\battle_matching\n",
      "Mkdir .\\dataset\\test\\battle_matching\n",
      "battle_matching 825 .\\dataset\\train 825\n",
      "battle_matching 275 .\\dataset\\val 275\n",
      "battle_matching 275 .\\dataset\\test 275\n",
      "battle_result 1265 [759, 253, 253]\n",
      "Mkdir .\\dataset\\train\\battle_result\n",
      "Mkdir .\\dataset\\val\\battle_result\n",
      "Mkdir .\\dataset\\test\\battle_result\n",
      "battle_result 759 .\\dataset\\train 759\n",
      "battle_result 253 .\\dataset\\val 253\n",
      "battle_result 253 .\\dataset\\test 253\n",
      "battle_rule 256 [153, 51, 51]\n",
      "Mkdir .\\dataset\\train\\battle_rule\n",
      "Mkdir .\\dataset\\val\\battle_rule\n",
      "Mkdir .\\dataset\\test\\battle_rule\n",
      "battle_rule 153 .\\dataset\\train 153\n",
      "battle_rule 51 .\\dataset\\val 51\n",
      "battle_rule 51 .\\dataset\\test 51\n",
      "battle_start 302 [181, 60, 60]\n",
      "Mkdir .\\dataset\\train\\battle_start\n",
      "Mkdir .\\dataset\\val\\battle_start\n",
      "Mkdir .\\dataset\\test\\battle_start\n",
      "battle_start 181 .\\dataset\\train 181\n",
      "battle_start 60 .\\dataset\\val 60\n",
      "battle_start 60 .\\dataset\\test 60\n",
      "loading 553 [331, 110, 110]\n",
      "Mkdir .\\dataset\\train\\loading\n",
      "Mkdir .\\dataset\\val\\loading\n",
      "Mkdir .\\dataset\\test\\loading\n",
      "loading 331 .\\dataset\\train 331\n",
      "loading 110 .\\dataset\\val 110\n",
      "loading 110 .\\dataset\\test 110\n",
      "menu 17 [10, 3, 3]\n",
      "Mkdir .\\dataset\\train\\menu\n",
      "Mkdir .\\dataset\\val\\menu\n",
      "Mkdir .\\dataset\\test\\menu\n",
      "menu 10 .\\dataset\\train 10\n",
      "menu 3 .\\dataset\\val 3\n",
      "menu 3 .\\dataset\\test 3\n",
      "other 16 [9, 3, 3]\n",
      "Mkdir .\\dataset\\train\\other\n",
      "Mkdir .\\dataset\\val\\other\n",
      "Mkdir .\\dataset\\test\\other\n",
      "other 9 .\\dataset\\train 9\n",
      "other 3 .\\dataset\\val 3\n",
      "other 3 .\\dataset\\test 3\n",
      "salmon 2664 [1598, 532, 532]\n",
      "Mkdir .\\dataset\\train\\salmon\n",
      "Mkdir .\\dataset\\val\\salmon\n",
      "Mkdir .\\dataset\\test\\salmon\n",
      "salmon 1598 .\\dataset\\train 1598\n",
      "salmon 532 .\\dataset\\val 532\n",
      "salmon 532 .\\dataset\\test 532\n",
      "salmon_lobby 17 [10, 3, 3]\n",
      "Mkdir .\\dataset\\train\\salmon_lobby\n",
      "Mkdir .\\dataset\\val\\salmon_lobby\n",
      "Mkdir .\\dataset\\test\\salmon_lobby\n",
      "salmon_lobby 10 .\\dataset\\train 10\n",
      "salmon_lobby 3 .\\dataset\\val 3\n",
      "salmon_lobby 3 .\\dataset\\test 3\n",
      "salmon_matching 128 [76, 25, 25]\n",
      "Mkdir .\\dataset\\train\\salmon_matching\n",
      "Mkdir .\\dataset\\val\\salmon_matching\n",
      "Mkdir .\\dataset\\test\\salmon_matching\n",
      "salmon_matching 76 .\\dataset\\train 76\n",
      "salmon_matching 25 .\\dataset\\val 25\n",
      "salmon_matching 25 .\\dataset\\test 25\n",
      "salmon_miss 23 [13, 4, 4]\n",
      "Mkdir .\\dataset\\train\\salmon_miss\n",
      "Mkdir .\\dataset\\val\\salmon_miss\n",
      "Mkdir .\\dataset\\test\\salmon_miss\n",
      "salmon_miss 13 .\\dataset\\train 13\n",
      "salmon_miss 4 .\\dataset\\val 4\n",
      "salmon_miss 4 .\\dataset\\test 4\n",
      "salmon_result 157 [94, 31, 31]\n",
      "Mkdir .\\dataset\\train\\salmon_result\n",
      "Mkdir .\\dataset\\val\\salmon_result\n",
      "Mkdir .\\dataset\\test\\salmon_result\n",
      "salmon_result 94 .\\dataset\\train 94\n",
      "salmon_result 31 .\\dataset\\val 31\n",
      "salmon_result 31 .\\dataset\\test 31\n",
      "salmon_start 79 [47, 15, 15]\n",
      "Mkdir .\\dataset\\train\\salmon_start\n",
      "Mkdir .\\dataset\\val\\salmon_start\n",
      "Mkdir .\\dataset\\test\\salmon_start\n",
      "salmon_start 47 .\\dataset\\train 47\n",
      "salmon_start 15 .\\dataset\\val 15\n",
      "salmon_start 15 .\\dataset\\test 15\n",
      "weapon_select 157 [94, 31, 31]\n",
      "Mkdir .\\dataset\\train\\weapon_select\n",
      "Mkdir .\\dataset\\val\\weapon_select\n",
      "Mkdir .\\dataset\\test\\weapon_select\n",
      "weapon_select 94 .\\dataset\\train 94\n",
      "weapon_select 31 .\\dataset\\val 31\n",
      "weapon_select 31 .\\dataset\\test 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugするたびに結果が変わるのはひとまず避けたい\n",
    "random.seed(0)\n",
    "\n",
    "# learn/validate/testに分離\n",
    "def split_dataset(src_base_path, dst_base_path, pathes, ratios, debug=False):\n",
    "    # すでに作成されている場合は一旦削除\n",
    "    if (os.path.exists(dst_base_path)):\n",
    "        shutil.rmtree(dst_base_path)\n",
    "    # ディレクトリ作成\n",
    "    os.mkdir(dst_base_path)\n",
    "    for p in pathes:\n",
    "        os.mkdir(p)\n",
    "    # ディレクトリ一覧取得\n",
    "    categories = list(filter(lambda x: \n",
    "                             os.path.isdir(os.path.join(src_base_path, x)) \n",
    "                             and not(x.startswith('.')),\n",
    "                     os.listdir(dataset_base_path)))\n",
    "    categories_n = len(categories) # 返却値にしてあげる\n",
    "    print(categories)\n",
    "    # 順番にコピーしてく\n",
    "    for c in categories:\n",
    "        files = os.listdir(os.path.join(src_base_path, c))\n",
    "        files_count = len(files)\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        ratio_sum = sum(ratios)\n",
    "        take_count = [int(files_count * (r / ratio_sum)) for r in ratios]\n",
    "        print(c, files_count, take_count)\n",
    "\n",
    "        for p in pathes:\n",
    "            dst = os.path.join(p, c)\n",
    "            if debug:\n",
    "                print('Mkdir {}'.format(dst))\n",
    "            os.mkdir(dst)\n",
    "            \n",
    "        count = 0\n",
    "        for t, p in zip(take_count, pathes):\n",
    "            target_files = files[count:count + t]\n",
    "            print(c, t, p, len(target_files))\n",
    "            src = [os.path.join(src_base_path, c, tf) for tf in target_files]\n",
    "            dst = [os.path.join(p, c, tf) for tf in target_files]\n",
    "            for s, d in zip(src, dst):\n",
    "                # print('Copy {} -> {}'.format(s, d))\n",
    "                shutil.copyfile(s, d)\n",
    "            count = t\n",
    "        if debug:\n",
    "            print('{} copy {} files'.format(c, count))\n",
    "    return categories_n\n",
    "        \n",
    "split_dataset(dataset_base_path, dataset_split_base_path, pathes, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\dataset\\train\n",
      "Found 10231 images belonging to 17 classes.\n",
      ".\\dataset\\val\n",
      "Found 3406 images belonging to 17 classes.\n",
      ".\\dataset\\test\n",
      "Found 3406 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# イメージをいい感じに読み込んでもらう\n",
    "def create_generator(path,\n",
    "                     target_size,\n",
    "                     batch_size,\n",
    "                     class_mode = 'categorical'):\n",
    "    print(path)\n",
    "    dg = ImageDataGenerator(rescale=1/255.0)\n",
    "    gen = dg.flow_from_directory(path, \n",
    "                                 target_size=target_size,\n",
    "                                 batch_size=batch_size,\n",
    "                                 class_mode=class_mode,\n",
    "                                 shuffle=True)\n",
    "    return (dg, gen)\n",
    "\n",
    "(train_dg, train_gen) = create_generator(dataset_train_path, target_size=input_size, batch_size=batch_size)\n",
    "(val_dg,   val_gen)   = create_generator(dataset_val_path, target_size=input_size, batch_size=batch_size)\n",
    "(test_dg,  test_gen)  = create_generator(dataset_test_path, target_size=input_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80, 45, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 80, 45, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 80, 45, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 40, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 40, 22, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 40, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 20, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 20, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 20, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 20, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 5, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 10, 5, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 10, 5, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 10, 5, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                17425     \n",
      "=================================================================\n",
      "Total params: 15,257,425\n",
      "Trainable params: 542,737\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGGの転移学習モデルを作る\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "def create_vgg16_base_model(categories_n):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    # VGG16自体は学習できないように凍結しておく\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = False\n",
    "    # あとにレイヤを追加\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(categories_n, activation='softmax')(x)\n",
    "    return Model(inputs= base_model.input, outputs=x)\n",
    "    \n",
    "model = create_vgg16_base_model(categories_n)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2558/2558 [==============================] - 75s 29ms/step - loss: 1.2096 - acc: 0.6430 - val_loss: 0.9955 - val_acc: 0.7173\n",
      "Epoch 2/500\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 0.8936 - acc: 0.7538 - val_loss: 0.7982 - val_acc: 0.7813\n",
      "Epoch 3/500\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 0.7489 - acc: 0.7885 - val_loss: 0.6983 - val_acc: 0.8048\n",
      "Epoch 4/500\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 0.6543 - acc: 0.8116 - val_loss: 0.6118 - val_acc: 0.8332\n",
      "Epoch 5/500\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 0.5844 - acc: 0.8324 - val_loss: 0.5626 - val_acc: 0.8438\n",
      "Epoch 6/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.5325 - acc: 0.8466 - val_loss: 0.5107 - val_acc: 0.8555\n",
      "Epoch 7/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.4932 - acc: 0.8601 - val_loss: 0.4728 - val_acc: 0.8705\n",
      "Epoch 8/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.4617 - acc: 0.8697 - val_loss: 0.4454 - val_acc: 0.8782\n",
      "Epoch 9/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.4369 - acc: 0.8776 - val_loss: 0.4302 - val_acc: 0.8776\n",
      "Epoch 10/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.4146 - acc: 0.8843 - val_loss: 0.4093 - val_acc: 0.8887\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.40927, saving model to ./best.hdf5\n",
      "Epoch 11/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.3967 - acc: 0.8893 - val_loss: 0.3859 - val_acc: 0.8937\n",
      "Epoch 12/500\n",
      "2558/2558 [==============================] - 60s 24ms/step - loss: 0.3807 - acc: 0.8931 - val_loss: 0.3829 - val_acc: 0.8993\n",
      "Epoch 13/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.3658 - acc: 0.8961 - val_loss: 0.3639 - val_acc: 0.8978\n",
      "Epoch 14/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.3551 - acc: 0.8972 - val_loss: 0.3482 - val_acc: 0.8990\n",
      "Epoch 15/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.3425 - acc: 0.8995 - val_loss: 0.3374 - val_acc: 0.9072\n",
      "Epoch 16/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.3332 - acc: 0.9030 - val_loss: 0.3303 - val_acc: 0.9031\n",
      "Epoch 17/500\n",
      "2558/2558 [==============================] - 60s 23ms/step - loss: 0.3230 - acc: 0.9053 - val_loss: 0.3381 - val_acc: 0.8943\n",
      "Epoch 18/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.3143 - acc: 0.9084 - val_loss: 0.3194 - val_acc: 0.9093\n",
      "Epoch 19/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.3074 - acc: 0.9080 - val_loss: 0.3056 - val_acc: 0.9166\n",
      "Epoch 20/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.2997 - acc: 0.9103 - val_loss: 0.2992 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.40927 to 0.29916, saving model to ./best.hdf5\n",
      "Epoch 21/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.2926 - acc: 0.9130 - val_loss: 0.3065 - val_acc: 0.9090\n",
      "Epoch 22/500\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 0.2867 - acc: 0.9145 - val_loss: 0.2917 - val_acc: 0.9201\n",
      "Epoch 23/500\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 0.2809 - acc: 0.9146 - val_loss: 0.2904 - val_acc: 0.9178\n",
      "Epoch 24/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2757 - acc: 0.9172 - val_loss: 0.2814 - val_acc: 0.9196\n",
      "Epoch 25/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2692 - acc: 0.9184 - val_loss: 0.2760 - val_acc: 0.9175\n",
      "Epoch 26/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2650 - acc: 0.9190 - val_loss: 0.2764 - val_acc: 0.9181\n",
      "Epoch 27/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2601 - acc: 0.9224 - val_loss: 0.2651 - val_acc: 0.9272\n",
      "Epoch 28/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2552 - acc: 0.9246 - val_loss: 0.2594 - val_acc: 0.9284\n",
      "Epoch 29/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2519 - acc: 0.9224 - val_loss: 0.2606 - val_acc: 0.9284\n",
      "Epoch 30/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2476 - acc: 0.9240 - val_loss: 0.2530 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.29916 to 0.25301, saving model to ./best.hdf5\n",
      "Epoch 31/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2424 - acc: 0.9260 - val_loss: 0.2705 - val_acc: 0.9178\n",
      "Epoch 32/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2401 - acc: 0.9277 - val_loss: 0.2486 - val_acc: 0.9328\n",
      "Epoch 33/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2373 - acc: 0.9275 - val_loss: 0.2415 - val_acc: 0.9325\n",
      "Epoch 34/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2340 - acc: 0.9304 - val_loss: 0.2448 - val_acc: 0.9369\n",
      "Epoch 35/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2315 - acc: 0.9299 - val_loss: 0.2358 - val_acc: 0.9351\n",
      "Epoch 36/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2280 - acc: 0.9297 - val_loss: 0.2332 - val_acc: 0.9319\n",
      "Epoch 37/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2239 - acc: 0.9322 - val_loss: 0.2313 - val_acc: 0.9348\n",
      "Epoch 38/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2224 - acc: 0.9328 - val_loss: 0.2313 - val_acc: 0.9319\n",
      "Epoch 39/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2195 - acc: 0.9329 - val_loss: 0.2487 - val_acc: 0.9231\n",
      "Epoch 40/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2164 - acc: 0.9334 - val_loss: 0.2421 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.25301 to 0.24208, saving model to ./best.hdf5\n",
      "Epoch 41/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2132 - acc: 0.9336 - val_loss: 0.2222 - val_acc: 0.9360\n",
      "Epoch 42/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2108 - acc: 0.9343 - val_loss: 0.2183 - val_acc: 0.9407\n",
      "Epoch 43/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2084 - acc: 0.9353 - val_loss: 0.2165 - val_acc: 0.9398\n",
      "Epoch 44/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2059 - acc: 0.9370 - val_loss: 0.2155 - val_acc: 0.9410\n",
      "Epoch 45/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2036 - acc: 0.9368 - val_loss: 0.2181 - val_acc: 0.9407\n",
      "Epoch 46/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.2016 - acc: 0.9360 - val_loss: 0.2124 - val_acc: 0.9401\n",
      "Epoch 47/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1994 - acc: 0.9378 - val_loss: 0.2286 - val_acc: 0.9310\n",
      "Epoch 48/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1983 - acc: 0.9391 - val_loss: 0.2085 - val_acc: 0.9425\n",
      "Epoch 49/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1954 - acc: 0.9371 - val_loss: 0.2077 - val_acc: 0.9442\n",
      "Epoch 50/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1928 - acc: 0.9398 - val_loss: 0.2047 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.24208 to 0.20473, saving model to ./best.hdf5\n",
      "Epoch 51/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1910 - acc: 0.9407 - val_loss: 0.2140 - val_acc: 0.9386\n",
      "Epoch 52/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1897 - acc: 0.9413 - val_loss: 0.2164 - val_acc: 0.9345\n",
      "Epoch 53/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1875 - acc: 0.9403 - val_loss: 0.2029 - val_acc: 0.9427\n",
      "Epoch 54/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1858 - acc: 0.9440 - val_loss: 0.2016 - val_acc: 0.9442\n",
      "Epoch 55/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1841 - acc: 0.9435 - val_loss: 0.2002 - val_acc: 0.9442\n",
      "Epoch 56/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1829 - acc: 0.9434 - val_loss: 0.1980 - val_acc: 0.9445\n",
      "Epoch 57/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1808 - acc: 0.9439 - val_loss: 0.2012 - val_acc: 0.9416\n",
      "Epoch 58/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1546 - acc: 0.9504 - val_loss: 0.1754 - val_acc: 0.9489\n",
      "Epoch 78/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1540 - acc: 0.9519 - val_loss: 0.1785 - val_acc: 0.9486\n",
      "Epoch 79/500\n",
      " 271/2558 [==>...........................] - ETA: 45s - loss: 0.1651 - acc: 0.9493Epoch 80/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1519 - acc: 0.9519 - val_loss: 0.1750 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.19448 to 0.17496, saving model to ./best.hdf5\n",
      "Epoch 81/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1495 - acc: 0.9519 - val_loss: 0.1743 - val_acc: 0.9486\n",
      "Epoch 82/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1474 - acc: 0.9547 - val_loss: 0.1915 - val_acc: 0.9395\n",
      "Epoch 84/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1458 - acc: 0.9539 - val_loss: 0.1849 - val_acc: 0.9425\n",
      "Epoch 85/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1460 - acc: 0.9537 - val_loss: 0.1713 - val_acc: 0.9492\n",
      "Epoch 86/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1420 - acc: 0.9528 - val_loss: 0.1738 - val_acc: 0.9466\n",
      "Epoch 89/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1415 - acc: 0.9564 - val_loss: 0.1671 - val_acc: 0.9513\n",
      "Epoch 90/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1414 - acc: 0.9561 - val_loss: 0.1690 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.17496 to 0.16904, saving model to ./best.hdf5\n",
      "Epoch 91/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1374 - acc: 0.9550 - val_loss: 0.1636 - val_acc: 0.9536\n",
      "Epoch 95/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1370 - acc: 0.9574 - val_loss: 0.1723 - val_acc: 0.9489\n",
      "Epoch 96/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1307 - acc: 0.9572 - val_loss: 0.1709 - val_acc: 0.9451\n",
      "Epoch 102/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1296 - acc: 0.9568 - val_loss: 0.1581 - val_acc: 0.9527\n",
      "Epoch 105/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1281 - acc: 0.9594 - val_loss: 0.1593 - val_acc: 0.9513\n",
      "Epoch 106/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1249 - acc: 0.9609 - val_loss: 0.1598 - val_acc: 0.9501\n",
      "Epoch 110/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1229 - acc: 0.9593 - val_loss: 0.1545 - val_acc: 0.9545\n",
      "Epoch 113/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1219 - acc: 0.9610 - val_loss: 0.1544 - val_acc: 0.9524\n",
      "Epoch 114/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1189 - acc: 0.9613 - val_loss: 0.1591 - val_acc: 0.9513\n",
      "Epoch 118/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1184 - acc: 0.9629 - val_loss: 0.1549 - val_acc: 0.9542\n",
      "Epoch 119/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1161 - acc: 0.9639 - val_loss: 0.1505 - val_acc: 0.9542\n",
      "Epoch 122/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1132 - acc: 0.9635 - val_loss: 0.1512 - val_acc: 0.9527\n",
      "Epoch 126/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1133 - acc: 0.9634 - val_loss: 0.1483 - val_acc: 0.9554\n",
      "Epoch 127/500\n",
      "1099/2558 [===========>..................] - ETA: 29s - loss: 0.1183 - acc: 0.9611Epoch 130/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1103 - acc: 0.9640 - val_loss: 0.1481 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.15061 to 0.14813, saving model to ./best.hdf5\n",
      "Epoch 131/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1080 - acc: 0.9659 - val_loss: 0.1570 - val_acc: 0.9492\n",
      "Epoch 135/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1053 - acc: 0.9670 - val_loss: 0.1702 - val_acc: 0.9419\n",
      "Epoch 138/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1057 - acc: 0.9671 - val_loss: 0.1482 - val_acc: 0.9563\n",
      "Epoch 139/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1019 - acc: 0.9689 - val_loss: 0.1437 - val_acc: 0.9565\n",
      "Epoch 143/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1013 - acc: 0.9682 - val_loss: 0.1449 - val_acc: 0.9551\n",
      "Epoch 144/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.1008 - acc: 0.9694 - val_loss: 0.1435 - val_acc: 0.9545\n",
      "Epoch 147/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0997 - acc: 0.9679 - val_loss: 0.1413 - val_acc: 0.9571\n",
      "Epoch 148/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0980 - acc: 0.9693 - val_loss: 0.1415 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.14354 to 0.14145, saving model to ./best.hdf5\n",
      "Epoch 151/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0987 - acc: 0.9702 - val_loss: 0.1422 - val_acc: 0.9548\n",
      "Epoch 152/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0952 - acc: 0.9701 - val_loss: 0.1418 - val_acc: 0.9554\n",
      "Epoch 156/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0930 - acc: 0.9718 - val_loss: 0.1375 - val_acc: 0.9580\n",
      "Epoch 160/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0920 - acc: 0.9713 - val_loss: 0.1411 - val_acc: 0.9551\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.14145 to 0.14111, saving model to ./best.hdf5\n",
      "Epoch 161/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0903 - acc: 0.9718 - val_loss: 0.1372 - val_acc: 0.9568\n",
      "Epoch 165/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0884 - acc: 0.9737 - val_loss: 0.1347 - val_acc: 0.9580\n",
      "Epoch 170/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0883 - acc: 0.9731 - val_loss: 0.1385 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.14111 to 0.13848, saving model to ./best.hdf5\n",
      "Epoch 171/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0861 - acc: 0.9738 - val_loss: 0.1374 - val_acc: 0.9557\n",
      "Epoch 174/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0854 - acc: 0.9740 - val_loss: 0.1330 - val_acc: 0.9595\n",
      "Epoch 175/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0844 - acc: 0.9744 - val_loss: 0.1358 - val_acc: 0.9560\n",
      "Epoch 180/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0813 - acc: 0.9764 - val_loss: 0.1333 - val_acc: 0.9577\n",
      "Epoch 184/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0811 - acc: 0.9758 - val_loss: 0.1325 - val_acc: 0.9592\n",
      "Epoch 185/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0785 - acc: 0.9771 - val_loss: 0.1323 - val_acc: 0.9580\n",
      "Epoch 189/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0781 - acc: 0.9772 - val_loss: 0.1300 - val_acc: 0.9601\n",
      "Epoch 193/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0772 - acc: 0.9768 - val_loss: 0.1325 - val_acc: 0.9571\n",
      "Epoch 194/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0758 - acc: 0.9772 - val_loss: 0.1305 - val_acc: 0.9577\n",
      "Epoch 198/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0748 - acc: 0.9788 - val_loss: 0.1284 - val_acc: 0.9615\n",
      "Epoch 199/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0750 - acc: 0.9788 - val_loss: 0.1280 - val_acc: 0.9598\n",
      "Epoch 202/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0745 - acc: 0.9790 - val_loss: 0.1294 - val_acc: 0.9624\n",
      "Epoch 203/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0718 - acc: 0.9807 - val_loss: 0.1427 - val_acc: 0.9504\n",
      "Epoch 207/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0709 - acc: 0.9802 - val_loss: 0.1336 - val_acc: 0.9574\n",
      "Epoch 208/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0698 - acc: 0.9803 - val_loss: 0.1284 - val_acc: 0.9612\n",
      "Epoch 212/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0691 - acc: 0.9812 - val_loss: 0.1297 - val_acc: 0.9618\n",
      "Epoch 216/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0684 - acc: 0.9806 - val_loss: 0.1265 - val_acc: 0.9627\n",
      "Epoch 217/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0668 - acc: 0.9804 - val_loss: 0.1258 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.12634 to 0.12579, saving model to ./best.hdf5\n",
      "Epoch 221/500\n",
      "2377/2558 [==========================>...] - ETA: 3s - loss: 0.0634 - acc: 0.9835Epoch 225/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0650 - acc: 0.9827 - val_loss: 0.1258 - val_acc: 0.9630\n",
      "Epoch 226/500\n",
      " 868/2558 [=========>....................] - ETA: 33s - loss: 0.0674 - acc: 0.9824Epoch 229/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0642 - acc: 0.9818 - val_loss: 0.1276 - val_acc: 0.9615\n",
      "Epoch 230/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0613 - acc: 0.9833 - val_loss: 0.1244 - val_acc: 0.9592\n",
      "Epoch 234/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0617 - acc: 0.9832 - val_loss: 0.1268 - val_acc: 0.9583\n",
      "Epoch 235/500\n",
      " 958/2558 [==========>...................] - ETA: 32s - loss: 0.0672 - acc: 0.9812Epoch 238/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0611 - acc: 0.9835 - val_loss: 0.1229 - val_acc: 0.9607\n",
      "Epoch 239/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0597 - acc: 0.9838 - val_loss: 0.1229 - val_acc: 0.9601\n",
      "Epoch 243/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0582 - acc: 0.9845 - val_loss: 0.1223 - val_acc: 0.9624\n",
      "Epoch 248/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0577 - acc: 0.9840 - val_loss: 0.1259 - val_acc: 0.9589\n",
      "Epoch 249/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0571 - acc: 0.9848 - val_loss: 0.1238 - val_acc: 0.9648\n",
      "Epoch 252/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0564 - acc: 0.9856 - val_loss: 0.1213 - val_acc: 0.9630\n",
      "Epoch 253/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0556 - acc: 0.9856 - val_loss: 0.1262 - val_acc: 0.9557\n",
      "Epoch 258/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0532 - acc: 0.9866 - val_loss: 0.1265 - val_acc: 0.9636\n",
      "Epoch 262/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0526 - acc: 0.9870 - val_loss: 0.1216 - val_acc: 0.9589\n",
      "Epoch 267/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0510 - acc: 0.9872 - val_loss: 0.1181 - val_acc: 0.9621\n",
      "Epoch 272/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0498 - acc: 0.9885 - val_loss: 0.1238 - val_acc: 0.9633\n",
      "Epoch 277/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0489 - acc: 0.9886 - val_loss: 0.1205 - val_acc: 0.9645\n",
      "Epoch 278/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0488 - acc: 0.9880 - val_loss: 0.1253 - val_acc: 0.9565\n",
      "Epoch 282/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0478 - acc: 0.9892 - val_loss: 0.1177 - val_acc: 0.9610\n",
      "Epoch 286/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0475 - acc: 0.9892 - val_loss: 0.1179 - val_acc: 0.9607\n",
      "Epoch 287/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0464 - acc: 0.9894 - val_loss: 0.1183 - val_acc: 0.9642\n",
      "Epoch 290/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0454 - acc: 0.9896 - val_loss: 0.1175 - val_acc: 0.9621\n",
      "Epoch 295/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0449 - acc: 0.9912 - val_loss: 0.1175 - val_acc: 0.9604\n",
      "Epoch 299/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0443 - acc: 0.9899 - val_loss: 0.1180 - val_acc: 0.9607\n",
      "Epoch 300/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0438 - acc: 0.9906 - val_loss: 0.1213 - val_acc: 0.9654\n",
      "Epoch 303/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0444 - acc: 0.9903 - val_loss: 0.1167 - val_acc: 0.9618\n",
      "Epoch 304/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0425 - acc: 0.9921 - val_loss: 0.1173 - val_acc: 0.9610\n",
      "Epoch 308/500\n",
      "2558/2558 [==============================] - 68s 26ms/step - loss: 0.0419 - acc: 0.9908 - val_loss: 0.1162 - val_acc: 0.9645\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.11678 to 0.11616, saving model to ./best.hdf5\n",
      "Epoch 311/500\n",
      "2558/2558 [==============================] - 68s 27ms/step - loss: 0.0410 - acc: 0.9917 - val_loss: 0.1233 - val_acc: 0.9577\n",
      "Epoch 312/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0407 - acc: 0.9923 - val_loss: 0.1183 - val_acc: 0.9595\n",
      "Epoch 316/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0403 - acc: 0.9917 - val_loss: 0.1168 - val_acc: 0.9601\n",
      "Epoch 322/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0382 - acc: 0.9923 - val_loss: 0.1168 - val_acc: 0.9633\n",
      "Epoch 328/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0371 - acc: 0.9933 - val_loss: 0.1159 - val_acc: 0.9615\n",
      "Epoch 335/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0364 - acc: 0.9927 - val_loss: 0.1148 - val_acc: 0.9636\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.11616 to 0.11476, saving model to ./best.hdf5\n",
      "Epoch 341/500\n",
      "1225/2558 [=============>................] - ETA: 26s - loss: 0.0378 - acc: 0.9931Epoch 347/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0347 - acc: 0.9937 - val_loss: 0.1174 - val_acc: 0.9636\n",
      "Epoch 348/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0341 - acc: 0.9936 - val_loss: 0.1144 - val_acc: 0.9618\n",
      "Epoch 353/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0341 - acc: 0.9936 - val_loss: 0.1190 - val_acc: 0.9645\n",
      "Epoch 354/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0327 - acc: 0.9940 - val_loss: 0.1186 - val_acc: 0.9615\n",
      "Epoch 360/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0315 - acc: 0.9950 - val_loss: 0.1222 - val_acc: 0.9659\n",
      "Epoch 367/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0314 - acc: 0.9941 - val_loss: 0.1147 - val_acc: 0.9630\n",
      "Epoch 373/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0301 - acc: 0.9953 - val_loss: 0.1178 - val_acc: 0.9654\n",
      "Epoch 379/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0298 - acc: 0.9958 - val_loss: 0.1158 - val_acc: 0.9648\n",
      "Epoch 380/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0286 - acc: 0.9956 - val_loss: 0.1152 - val_acc: 0.9648\n",
      "Epoch 385/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0288 - acc: 0.9962 - val_loss: 0.1171 - val_acc: 0.9639\n",
      "Epoch 386/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0284 - acc: 0.9961 - val_loss: 0.1153 - val_acc: 0.9633\n",
      "Epoch 392/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0275 - acc: 0.9961 - val_loss: 0.1178 - val_acc: 0.9589\n",
      "Epoch 398/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0267 - acc: 0.9965 - val_loss: 0.1148 - val_acc: 0.9639\n",
      "Epoch 405/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0262 - acc: 0.9965 - val_loss: 0.1248 - val_acc: 0.9642\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.11407\n",
      "Epoch 411/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0253 - acc: 0.9966 - val_loss: 0.1145 - val_acc: 0.9615\n",
      "Epoch 418/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0246 - acc: 0.9968 - val_loss: 0.1138 - val_acc: 0.9642\n",
      "Epoch 425/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0241 - acc: 0.9972 - val_loss: 0.1131 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.11407 to 0.11312, saving model to ./best.hdf5\n",
      "Epoch 431/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0235 - acc: 0.9969 - val_loss: 0.1156 - val_acc: 0.9659\n",
      "Epoch 437/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0225 - acc: 0.9975 - val_loss: 0.1141 - val_acc: 0.9624\n",
      "Epoch 444/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0221 - acc: 0.9977 - val_loss: 0.1152 - val_acc: 0.9607\n",
      "Epoch 450/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0212 - acc: 0.9978 - val_loss: 0.1147 - val_acc: 0.9636\n",
      "Epoch 456/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0210 - acc: 0.9975 - val_loss: 0.1138 - val_acc: 0.9636\n",
      "Epoch 463/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0208 - acc: 0.9975 - val_loss: 0.1147 - val_acc: 0.9627\n",
      "Epoch 469/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0201 - acc: 0.9982 - val_loss: 0.1190 - val_acc: 0.9665\n",
      "Epoch 470/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0200 - acc: 0.9978 - val_loss: 0.1147 - val_acc: 0.9642\n",
      "Epoch 476/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0195 - acc: 0.9980 - val_loss: 0.1156 - val_acc: 0.9639\n",
      "Epoch 482/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0186 - acc: 0.9988 - val_loss: 0.1158 - val_acc: 0.9645\n",
      "Epoch 488/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0187 - acc: 0.9985 - val_loss: 0.1145 - val_acc: 0.9627\n",
      "Epoch 489/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0185 - acc: 0.9982 - val_loss: 0.1149 - val_acc: 0.9636\n",
      "Epoch 495/500\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 0.0183 - acc: 0.9981 - val_loss: 0.1150 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.11312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba68aa4c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習する\n",
    "tb_cb = TensorBoard(log_dir=tensorboard_log_path)\n",
    "checkpointer = ModelCheckpoint(filepath='./best.hdf5', verbose=1, save_best_only=True, period=10, save_weights_only=False)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    epochs = 500,\n",
    "    verbose = 1,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=128,\n",
    "    callbacks=[tb_cb, checkpointer],\n",
    ")\n",
    "model.save('model.h5')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852/852 [==============================] - 16s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016905705805647167, 0.9991192014092778]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータで性能確認\n",
    "result = model.evaluate_generator(\n",
    "    test_gen,\n",
    "    verbose=1\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "ml3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
